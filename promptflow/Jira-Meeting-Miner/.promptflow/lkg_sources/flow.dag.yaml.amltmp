id: template_standard_flow
name: Template Standard Flow
inputs:
  blobs:
    type: list
    default:
    - transcript-1.txt
    is_chat_input: false
outputs:
  result:
    type: string
    reference: ${user_story_generator.output}
nodes:
- name: langchain_summarization
  type: python
  source:
    type: code
    path: langchain_summarization.py
  inputs:
    azure_open_ai_connection: openai-integrations
    chunks: ${generate_chunks.output}
  use_variants: false
- name: get_blob_content
  type: python
  source:
    type: code
    path: echo.py
  inputs:
    conn: blob-connection
    blob_names: ${inputs.blobs}
  use_variants: false
- name: generate_chunks
  type: python
  source:
    type: code
    path: generate_chunks.py
  inputs:
    content: ${get_blob_content.output}
  use_variants: false
- name: user_story_generator
  type: llm
  source:
    type: code
    path: summarization_prompt.jinja2
  inputs:
    deployment_name: ChatGPT-OpenAI
    temperature: 0.3
    top_p: 1
    stop: ""
    max_tokens: 0
    presence_penalty: 0
    frequency_penalty: 0
    logit_bias: ""
    text: ${langchain_summarization.output}
  provider: AzureOpenAI
  connection: openai-integrations
  api: chat
  module: promptflow.tools.aoai
  use_variants: false
node_variants: {}
environment:
  python_requirements_txt: requirements.txt
